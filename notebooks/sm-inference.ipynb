{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a Scikit-learn Model in Amazon Sagemaker\n",
    "This notebook shows how to deploy a model in Sagemaker.\n",
    "\n",
    "- Kernel: Python 3 (Data Science)\n",
    "\n",
    "## Step 1: Prepare SageMaker model\n",
    "SageMaker expects model into `model.tar.gz` format. Convert you model that you trained outside SageMaker into a sagemaker model\n",
    "\n",
    "`tar -czf model.tar.gz ./<directory-with-model-files>`\n",
    "\n",
    "Once you have `model.tar.gz`, then upload it into S3, copy the uploaded S3 URI, this URI is you model data artifact\n",
    "\n",
    "## Step 2: Host the model\n",
    "To host a model in SageMaker via `SageMaker Scikit-learn Model Server`, you need to override four function in your inference entrypoint script.\n",
    "\n",
    "### 1. `def model_fn(model_dir)`:\n",
    "\n",
    "This function load the model. Before a model can be served, it must be loaded. The SageMaker Scikit-learn model server loads your model by invoking a model_fn function that you must provide in your script.\n",
    "\n",
    "### 2. `def input_fn(request_body, request_content_type)`:\n",
    "\n",
    "Takes request data and deserializes the data into an object for prediction.\n",
    "\n",
    "### 3. `def predict_fn(input_object, model)`:\n",
    "\n",
    "Takes the deserialized request object and performs inference against the loaded model.\n",
    "\n",
    "### 4. `def output_fn(prediction, response_content_type)`:\n",
    "\n",
    "Takes the result of prediction and serializes this according to the response content type.\n",
    "\n",
    "## Step 3: Once you inference script is ready execute this notebook to a create model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"<S3_BUCKET_NAME>\"\n",
    "INSTANCE_TYPE = \"ml.m5.large\"\n",
    "INSTANCE_COUNT = 1\n",
    "MODEL_ARTIFACT_URI = \"s3://<S3_BUCKET_NAME>/test/mark-test/upw-test/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.session\n",
    "from trlabs_mltools.scw import Workspace\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "model_name = \"COVID-Risk-Predictor-Model\"\n",
    "session = sagemaker.session.Session(default_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SKLearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Session\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=MODEL_ARTIFACT_URI,\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    name=model_name,\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"risk_predictor_sm.py\",\n",
    "    framework_version=\"0.20.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sklearn_model.deploy(\n",
    "    instance_type=INSTANCE_TYPE, \n",
    "    initial_instance_count=INSTANCE_COUNT,\n",
    "    tags=workspace.tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prediction from the model endpint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "sm_runtime= boto3.client('runtime.sagemaker')\n",
    "endpoint_name = predictor.endpoint_name\n",
    "\n",
    "def get_prediction(np_array):\n",
    "    np_bytes = BytesIO()\n",
    "    np.save(np_bytes, np_array, allow_pickle=True)\n",
    "    np_bytes = np_bytes.getvalue()\n",
    "\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        Body=np_bytes, \n",
    "        ContentType=\"application/x-npy\",\n",
    "        Accept=\"application/x-npy\"\n",
    "    )\n",
    "\n",
    "    resp_bytes = BytesIO(response['Body'].read())\n",
    "    output_data = np.load(resp_bytes, allow_pickle=True)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.genfromtxt('~/Data/X_test.csv', delimiter=',', skip_header=1)\n",
    "y = get_prediction(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "response = sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Delete endpoint response: {response}\")\n",
    "\n",
    "response = sm.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "print(f\"Delete endpoint configuration response: {response}\")\n",
    "\n",
    "response = sm.delete_model(ModelName=model_name)\n",
    "print(f\"Delete model response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
